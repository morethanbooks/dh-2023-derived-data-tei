{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.abspath(\"C:/Users/calvotello/Dropbox/Doktorarbeit/novelasespanolas/code/\"))\n",
    "sys.path.append(os.path.abspath(\"./../functions/\"))\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from lxml import etree\n",
    "import glob\n",
    "import random\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespaces = {'tei':'http://www.tei-c.org/ns/1.0','cligs':'https://cligs.hypotheses.org/ns/cligs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_element(document, element, namespaces = namespaces):\n",
    "    for bad in document.xpath(\"//tei:\" + element, namespaces=namespaces):\n",
    "        bad.getparent().remove(bad)\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_text(document, elements = [\"l\", \"ab\", \"p\", \"stage\"], namespaces = namespaces):\n",
    "      xpath = \" or \".join([\"self::tei:\" + element for element in elements ])\n",
    "\n",
    "      for element in document.xpath(\"//*[\" + xpath +\"]\", namespaces=namespaces):\n",
    "            element.text = \"\"\n",
    "      return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './../data/tei-annotated-id/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_gb14397\n",
      "en_amdram1\n",
      "es_ne0120\n",
      "fr_Aarons_Attila\n",
      "zh_Luxun_Kuangren\n"
     ]
    }
   ],
   "source": [
    "for doc_str in glob.glob(input_dir + \"*.xml\"):\n",
    "    file_name  = os.path.splitext(os.path.split(doc_str)[1])[0]\n",
    "    print(file_name)\n",
    "\n",
    "    document = etree.parse(input_dir + file_name + '.xml')\n",
    "\n",
    "    document = delete_element(document, \"measure\")\n",
    "\n",
    "    fileDesc = document.xpath('//tei:fileDesc', namespaces=namespaces)[0]\n",
    "\n",
    "    extent = etree.SubElement(fileDesc, \"extent\") \n",
    "\n",
    "    measureGrp = etree.SubElement(extent, \"measureGrp\") \n",
    "\n",
    "    measureGrp.attrib['type'] = \"form\"\n",
    "\n",
    "    for element in document.xpath('/tei:TEI/tei:text/tei:body', namespaces=namespaces):\n",
    "        #print(element.xpath(\"./@xml:id\", namespaces=namespaces))\n",
    "\n",
    "        measureGrp_chapter = etree.SubElement(measureGrp, \"measureGrp\")\n",
    "\n",
    "        measureGrp_chapter.attrib['corresp'] = \"#\" + file_name[3:]\n",
    "\n",
    "        for key, value in dict(Counter(element.xpath(\".//tei:w/text() | .//tei:pc/text()\", namespaces=namespaces)).most_common()).items():\n",
    "\n",
    "            measure = etree.SubElement(measureGrp_chapter, \"measure\")\n",
    "            measure.attrib['commodity'] = key\n",
    "            measure.attrib['quantity'] = str(value)\n",
    "\n",
    "    #document = delete_text(document)\n",
    "    document = delete_element(document, element = \"w\")\n",
    "    document = delete_element(document, element = \"pc\")\n",
    "\n",
    "    document.write('./../data/derived/volume_' + file_name + '.xml', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_gb14397\n",
      "gb14397_chap1\n",
      "gb14397_chap2\n",
      "gb14397_chap3\n",
      "gb14397_chap4\n",
      "gb14397_chap5\n",
      "gb14397_chap6\n",
      "gb14397_chap7\n",
      "gb14397_chap8\n",
      "gb14397_chap9\n",
      "gb14397_chap10\n",
      "gb14397_chap11\n",
      "gb14397_chap12\n",
      "gb14397_chap13\n",
      "gb14397_chap14\n",
      "gb14397_chap15\n",
      "gb14397_chap16\n",
      "en_amdram1\n",
      "emdram1_act1\n",
      "emdram1_act2\n",
      "es_ne0120\n",
      "ne0120_chap1\n",
      "ne0120_chap2\n",
      "ne0120_chap3\n",
      "ne0120_chap4\n",
      "fr_Aarons_Attila\n",
      "Aarons_Attila_ch01\n",
      "Aarons_Attila_ch02\n",
      "Aarons_Attila_ch03\n",
      "Aarons_Attila_ch04\n",
      "Aarons_Attila_ch05\n",
      "Aarons_Attila_ch06\n",
      "Aarons_Attila_ch07\n",
      "Aarons_Attila_ch08\n",
      "Aarons_Attila_ch09\n",
      "Aarons_Attila_ch10\n",
      "Aarons_Attila_ch11\n",
      "Aarons_Attila_ch12\n",
      "Aarons_Attila_ch13\n",
      "zh_Luxun_Kuangren\n",
      "Luxun_Kuangren_ch00\n",
      "Luxun_Kuangren_ch01\n",
      "Luxun_Kuangren_ch02\n",
      "Luxun_Kuangren_ch03\n",
      "Luxun_Kuangren_ch04\n",
      "Luxun_Kuangren_ch05\n",
      "Luxun_Kuangren_ch06\n",
      "Luxun_Kuangren_ch07\n",
      "Luxun_Kuangren_ch08\n",
      "Luxun_Kuangren_ch09\n",
      "Luxun_Kuangren_ch10\n",
      "Luxun_Kuangren_ch11\n",
      "Luxun_Kuangren_ch012\n",
      "Luxun_Kuangren_ch13\n"
     ]
    }
   ],
   "source": [
    "for doc_str in glob.glob(input_dir + \"*.xml\"):\n",
    "    file_name  = os.path.splitext(os.path.split(doc_str)[1])[0]\n",
    "    print(file_name)\n",
    "\n",
    "    document = etree.parse(input_dir + file_name + '.xml')\n",
    "\n",
    "    document = delete_element(document, \"measure\")\n",
    "\n",
    "    fileDesc = document.xpath('//tei:fileDesc', namespaces = namespaces)[0]\n",
    "\n",
    "    extent = etree.SubElement(fileDesc, \"extent\") \n",
    "\n",
    "    measureGrp = etree.SubElement(extent, \"measureGrp\") \n",
    "\n",
    "    measureGrp.attrib['type'] = \"form\"\n",
    "\n",
    "    for div in document.xpath('//tei:body//tei:div[@type=\"chapter\"] | //tei:body//tei:div[@type=\"act\"]', namespaces = namespaces):\n",
    "        #print(div.xpath(\".//@xml:id\", namespaces = namespaces))\n",
    "        #print(div.xpath(\".//tei:w/@lemma\", namespaces=namespaces))\n",
    "        #print(Counter(div.xpath(\".//tei:anno[@type='tokens']//tei:w/@lemma\", namespaces=namespaces)))\n",
    "        print(div.xpath(\"./@xml:id\", namespaces = namespaces)[0])\n",
    "        measureGrp_chapter = etree.SubElement(measureGrp, \"measureGrp\") #nsmap = {\"tei\" : \"http://www.tei-c.org/ns/1.0\"})\n",
    "\n",
    "        measureGrp_chapter.attrib['corresp'] = \"#\" + div.xpath(\"./@xml:id\", namespaces = namespaces)[0]\n",
    "\n",
    "        for key, value in dict(Counter(div.xpath(\".//tei:w/text() | .//tei:pc/text()\", namespaces = namespaces)).most_common()).items():\n",
    "            #print(key)\n",
    "            measure = etree.SubElement(measureGrp_chapter, \"measure\")\n",
    "            measure.attrib['commodity'] = key\n",
    "            measure.attrib['quantity'] = str(value)\n",
    "\n",
    "    document = delete_element(document, element = \"w\")\n",
    "    document = delete_element(document, element = \"pc\")\n",
    "\n",
    "    document.write('./../data/derived/division_' + file_name + '.xml', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(Counter(element.xpath(\".//tei:w/text() | .//tei:pc/text()\", namespaces = namespaces)).most_common()).items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paragraph Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_gb14397\n",
      "en_amdram1\n",
      "es_ne0120\n",
      "fr_Aarons_Attila\n",
      "zh_Luxun_Kuangren\n"
     ]
    }
   ],
   "source": [
    "for doc_str in glob.glob(input_dir + \"*.xml\"):\n",
    "    file_name  = os.path.splitext(os.path.split(doc_str)[1])[0]\n",
    "    print(file_name)\n",
    "\n",
    "    document = etree.parse(input_dir + file_name + '.xml')\n",
    "\n",
    "\n",
    "    document = delete_element(document, \"measure\")\n",
    "\n",
    "    extent = document.xpath('//tei:extent', namespaces=namespaces)[0]\n",
    "\n",
    "    measureGrp = etree.SubElement(extent, \"measureGrp\") #nsmap = {\"tei\" : \"http://www.tei-c.org/ns/1.0\"})\n",
    "\n",
    "    measureGrp.attrib['type'] = \"form\"\n",
    "\n",
    "    for p in document.xpath('//tei:body//tei:div[@type=\"chapter\"]//tei:p | //tei:body//tei:div[@type=\"chapter\"]//tei:ab | //tei:body//tei:div[@type=\"act\"]//tei:stage | //tei:body//tei:div[@type=\"act\"]//tei:p', namespaces=namespaces):\n",
    "        #print(p.xpath(\"./@xml:id\", namespaces=namespaces))\n",
    "\n",
    "        measureGrp_chapter = etree.SubElement(measureGrp, \"measureGrp\") #nsmap = {\"tei\" : \"http://www.tei-c.org/ns/1.0\"})\n",
    "\n",
    "        measureGrp_chapter.attrib['corresp'] = \"#\" + p.xpath(\"./@xml:id\", namespaces=namespaces)[0]\n",
    "\n",
    "\n",
    "        for key, value in dict(Counter(p.xpath(\".//tei:w/text() | .//tei:pc/text()\", namespaces=namespaces)).most_common()).items():\n",
    "        \n",
    "            measure = etree.SubElement(measureGrp_chapter, \"measure\")\n",
    "            measure.attrib['commodity'] = key\n",
    "            measure.attrib['quantity'] = str(value)\n",
    "\n",
    "    document = delete_element(document, element = \"w\")\n",
    "    document = delete_element(document, element = \"pc\")\n",
    "\n",
    "    document.write('./../data/derived/paragraph_' + file_name + '.xml', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(Counter(p.xpath(\".//tei:w/text() | .//tei:pc/text()\", namespaces=namespaces)).most_common()).items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_gb14397\n",
      "['gb14397_chap1']\n",
      "['gb14397_chap2']\n",
      "['gb14397_chap3']\n",
      "['gb14397_chap4']\n",
      "['gb14397_chap5']\n",
      "['gb14397_chap6']\n",
      "['gb14397_chap7']\n",
      "['gb14397_chap8']\n",
      "['gb14397_chap9']\n",
      "['gb14397_chap10']\n",
      "['gb14397_chap11']\n",
      "['gb14397_chap12']\n",
      "['gb14397_chap13']\n",
      "['gb14397_chap14']\n",
      "['gb14397_chap15']\n",
      "['gb14397_chap16']\n",
      "en_amdram1\n",
      "['emdram1_act1']\n",
      "['emdram1_act2']\n",
      "es_ne0120\n",
      "['ne0120_chap1']\n",
      "['ne0120_chap2']\n",
      "['ne0120_chap3']\n",
      "['ne0120_chap4']\n",
      "fr_Aarons_Attila\n",
      "['Aarons_Attila_ch01']\n",
      "['Aarons_Attila_ch02']\n",
      "['Aarons_Attila_ch03']\n",
      "['Aarons_Attila_ch04']\n",
      "['Aarons_Attila_ch05']\n",
      "['Aarons_Attila_ch06']\n",
      "['Aarons_Attila_ch07']\n",
      "['Aarons_Attila_ch08']\n",
      "['Aarons_Attila_ch09']\n",
      "['Aarons_Attila_ch10']\n",
      "['Aarons_Attila_ch11']\n",
      "['Aarons_Attila_ch12']\n",
      "['Aarons_Attila_ch13']\n",
      "zh_Luxun_Kuangren\n",
      "['Luxun_Kuangren_ch00']\n",
      "['Luxun_Kuangren_ch01']\n",
      "['Luxun_Kuangren_ch02']\n",
      "['Luxun_Kuangren_ch03']\n",
      "['Luxun_Kuangren_ch04']\n",
      "['Luxun_Kuangren_ch05']\n",
      "['Luxun_Kuangren_ch06']\n",
      "['Luxun_Kuangren_ch07']\n",
      "['Luxun_Kuangren_ch08']\n",
      "['Luxun_Kuangren_ch09']\n",
      "['Luxun_Kuangren_ch10']\n",
      "['Luxun_Kuangren_ch11']\n",
      "['Luxun_Kuangren_ch012']\n",
      "['Luxun_Kuangren_ch13']\n"
     ]
    }
   ],
   "source": [
    "for doc_str in glob.glob(input_dir + \"*.xml\"):\n",
    "    file_name  = os.path.splitext(os.path.split(doc_str)[1])[0]\n",
    "    print(file_name)\n",
    "\n",
    "    document = etree.parse(input_dir + file_name + '.xml')\n",
    "\n",
    "\n",
    "    document = delete_element(document, \"measure\")\n",
    "\n",
    "    for div in document.xpath('//tei:body//tei:div[@type=\"chapter\"] | //tei:body//tei:div[@type=\"act\"]', namespaces=namespaces):\n",
    "        print(div.xpath(\"./@xml:id\", namespaces=namespaces))\n",
    "        #print(div.xpath(\".//tei:w/@lemma\", namespaces=namespaces))\n",
    "        #print(Counter(div.xpath(\".//tei:anno[@type='tokens']//tei:w/@lemma\", namespaces=namespaces)))\n",
    "\n",
    "        for paragraph in div.xpath(\"./tei:ab | ./tei:p | ./tei:stage\", namespaces=namespaces):\n",
    "                    \n",
    "                tokens = paragraph.xpath(\".//tei:w | .//tei:pc\", namespaces=namespaces)\n",
    "                \n",
    "                \n",
    "                random.shuffle(tokens)\n",
    "                for token in tokens:\n",
    "                    paragraph.append(token)\n",
    "\n",
    "\n",
    "    document.write('./../data/derived/random_' + file_name + '.xml', encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alphabetical Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_gb14397\n",
      "['gb14397_chap1']\n",
      "['gb14397_chap2']\n",
      "['gb14397_chap3']\n",
      "['gb14397_chap4']\n",
      "['gb14397_chap5']\n",
      "['gb14397_chap6']\n",
      "['gb14397_chap7']\n",
      "['gb14397_chap8']\n",
      "['gb14397_chap9']\n",
      "['gb14397_chap10']\n",
      "['gb14397_chap11']\n",
      "['gb14397_chap12']\n",
      "['gb14397_chap13']\n",
      "['gb14397_chap14']\n",
      "['gb14397_chap15']\n",
      "['gb14397_chap16']\n",
      "en_amdram1\n",
      "['emdram1_act1']\n",
      "['emdram1_act2']\n",
      "es_ne0120\n",
      "['ne0120_chap1']\n",
      "['ne0120_chap2']\n",
      "['ne0120_chap3']\n",
      "['ne0120_chap4']\n",
      "fr_Aarons_Attila\n",
      "['Aarons_Attila_ch01']\n",
      "['Aarons_Attila_ch02']\n",
      "['Aarons_Attila_ch03']\n",
      "['Aarons_Attila_ch04']\n",
      "['Aarons_Attila_ch05']\n",
      "['Aarons_Attila_ch06']\n",
      "['Aarons_Attila_ch07']\n",
      "['Aarons_Attila_ch08']\n",
      "['Aarons_Attila_ch09']\n",
      "['Aarons_Attila_ch10']\n",
      "['Aarons_Attila_ch11']\n",
      "['Aarons_Attila_ch12']\n",
      "['Aarons_Attila_ch13']\n",
      "zh_Luxun_Kuangren\n",
      "['Luxun_Kuangren_ch00']\n",
      "['Luxun_Kuangren_ch01']\n",
      "['Luxun_Kuangren_ch02']\n",
      "['Luxun_Kuangren_ch03']\n",
      "['Luxun_Kuangren_ch04']\n",
      "['Luxun_Kuangren_ch05']\n",
      "['Luxun_Kuangren_ch06']\n",
      "['Luxun_Kuangren_ch07']\n",
      "['Luxun_Kuangren_ch08']\n",
      "['Luxun_Kuangren_ch09']\n",
      "['Luxun_Kuangren_ch10']\n",
      "['Luxun_Kuangren_ch11']\n",
      "['Luxun_Kuangren_ch012']\n",
      "['Luxun_Kuangren_ch13']\n"
     ]
    }
   ],
   "source": [
    "for doc_str in glob.glob(input_dir + \"*.xml\"):\n",
    "    file_name  = os.path.splitext(os.path.split(doc_str)[1])[0]\n",
    "    print(file_name)\n",
    "\n",
    "    document = etree.parse(input_dir + file_name + '.xml')\n",
    "\n",
    "\n",
    "    document = delete_element(document, \"measure\")\n",
    "\n",
    "    for div in document.xpath('//tei:body//tei:div[@type=\"chapter\"] | //tei:body//tei:div[@type=\"act\"]', namespaces=namespaces):\n",
    "        print(div.xpath(\"./@xml:id\", namespaces=namespaces))\n",
    "        #print(div.xpath(\".//tei:w/@lemma\", namespaces=namespaces))\n",
    "        #print(Counter(div.xpath(\".//tei:anno[@type='tokens']//tei:w/@lemma\", namespaces=namespaces)))\n",
    "\n",
    "        for paragraph in div.xpath(\"./tei:ab | ./tei:p | ./tei:stage\", namespaces=namespaces):\n",
    "                    \n",
    "                tokens = paragraph.xpath(\".//tei:w | .//tei:pc\", namespaces=namespaces)\n",
    "                \n",
    "                tokens_lt = [[token, token.xpath('.//text()')[0]] for token in tokens]\n",
    "                tokens_lt = sorted(tokens_lt, key=operator.itemgetter(1))\n",
    "                sorted_tokens = [token[0] for token in tokens_lt]\n",
    "\n",
    "                for token in sorted_tokens:\n",
    "                    paragraph.append(token)\n",
    "\n",
    "\n",
    "    document.write('./../data/derived/alphabetical_' + file_name + '.xml', encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unordered grams of ordered tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_gb14397\n",
      "['gb14397_chap1']\n",
      "['gb14397_chap2']\n",
      "['gb14397_chap3']\n",
      "['gb14397_chap4']\n",
      "['gb14397_chap5']\n",
      "['gb14397_chap6']\n",
      "['gb14397_chap7']\n",
      "['gb14397_chap8']\n",
      "['gb14397_chap9']\n",
      "['gb14397_chap10']\n",
      "['gb14397_chap11']\n",
      "['gb14397_chap12']\n",
      "['gb14397_chap13']\n",
      "['gb14397_chap14']\n",
      "['gb14397_chap15']\n",
      "['gb14397_chap16']\n",
      "en_amdram1\n",
      "['emdram1_act1']\n",
      "['emdram1_act2']\n",
      "es_ne0120\n",
      "['ne0120_chap1']\n",
      "['ne0120_chap2']\n",
      "['ne0120_chap3']\n",
      "['ne0120_chap4']\n",
      "fr_Aarons_Attila\n",
      "['Aarons_Attila_ch01']\n",
      "['Aarons_Attila_ch02']\n",
      "['Aarons_Attila_ch03']\n",
      "['Aarons_Attila_ch04']\n",
      "['Aarons_Attila_ch05']\n",
      "['Aarons_Attila_ch06']\n",
      "['Aarons_Attila_ch07']\n",
      "['Aarons_Attila_ch08']\n",
      "['Aarons_Attila_ch09']\n",
      "['Aarons_Attila_ch10']\n",
      "['Aarons_Attila_ch11']\n",
      "['Aarons_Attila_ch12']\n",
      "['Aarons_Attila_ch13']\n",
      "zh_Luxun_Kuangren\n",
      "['Luxun_Kuangren_ch00']\n",
      "['Luxun_Kuangren_ch01']\n",
      "['Luxun_Kuangren_ch02']\n",
      "['Luxun_Kuangren_ch03']\n",
      "['Luxun_Kuangren_ch04']\n",
      "['Luxun_Kuangren_ch05']\n",
      "['Luxun_Kuangren_ch06']\n",
      "['Luxun_Kuangren_ch07']\n",
      "['Luxun_Kuangren_ch08']\n",
      "['Luxun_Kuangren_ch09']\n",
      "['Luxun_Kuangren_ch10']\n",
      "['Luxun_Kuangren_ch11']\n",
      "['Luxun_Kuangren_ch012']\n",
      "['Luxun_Kuangren_ch13']\n"
     ]
    }
   ],
   "source": [
    "for doc_str in glob.glob(input_dir + \"*.xml\"):\n",
    "    file_name  = os.path.splitext(os.path.split(doc_str)[1])[0]\n",
    "    print(file_name)\n",
    "\n",
    "    document = etree.parse(input_dir + file_name + '.xml')\n",
    "\n",
    "    for div in document.xpath('//tei:body//tei:div[@type=\"chapter\"] | //tei:body//tei:div[@type=\"act\"]', namespaces=namespaces):\n",
    "        print(div.xpath(\"./@xml:id\", namespaces=namespaces))\n",
    "\n",
    "        for paragraph in div.xpath(\".//tei:ab | .//tei:p | .//tei:stage\", namespaces=namespaces):\n",
    "            tokens = paragraph.xpath(\".//tei:w | .//tei:pc\", namespaces=namespaces)\n",
    "            \n",
    "            ngrams_lt = list(chunks(tokens, 3))\n",
    "            \n",
    "            random.shuffle(ngrams_lt)\n",
    "            for ngram in ngrams_lt:\n",
    "                \n",
    "                ngram_seg = etree.SubElement(paragraph, \"seg\") #nsmap = {\"tei\" : \"http://www.tei-c.org/ns/1.0\"})\n",
    "\n",
    "                for token in ngram:\n",
    "                    ngram_seg.append(token)\n",
    "\n",
    "    document.write('./../data/derived/random_trigrams_ordered_tokens_' + file_name + '.xml', encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f47a9bd213414a99a19c677dbc3fe06cd2e784c4236a07176834505119fd1ea8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
